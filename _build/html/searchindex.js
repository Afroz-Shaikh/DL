Search.setIndex({docnames:["Extra/Reinforcement Learning","Extra/index","Part 2 (Modern Practical Deep Networks)/Optimization for Training Deep Models/Batch Normalization","Part 2 (Modern Practical Deep Networks)/Optimization for Training Deep Models/index","Part 2 (Modern Practical Deep Networks)/index","index"],envversion:{"sphinx.domains.c":1,"sphinx.domains.changeset":1,"sphinx.domains.cpp":1,"sphinx.domains.javascript":1,"sphinx.domains.math":2,"sphinx.domains.python":1,"sphinx.domains.rst":1,"sphinx.domains.std":1,sphinx:55},filenames:["Extra/Reinforcement Learning.rst","Extra/index.rst","Part 2 (Modern Practical Deep Networks)/Optimization for Training Deep Models/Batch Normalization.rst","Part 2 (Modern Practical Deep Networks)/Optimization for Training Deep Models/index.rst","Part 2 (Modern Practical Deep Networks)/index.rst","index.rst"],objects:{},objnames:{},objtypes:{},terms:{"\ufb01nal":4,"\ufb01rst":4,"case":4,"class":2,"function":[2,4],"import":4,"long":2,"speci\ufb01":4,"try":4,For:[2,4],One:2,The:4,Then:2,There:2,These:4,_out:2,add:2,algorithm:4,also:4,applic:4,approxim:4,assign:2,backpropag:2,backward:2,bacth:2,basic:4,batch:[3,4],becaus:4,becauseth:[],behavior:4,below:2,best:4,between:2,bold:[],boldsymbol:4,book:3,both:2,calcul:2,call:5,can:2,categori:4,chain:4,chapter:5,choos:2,classifi:4,close:4,com:[],combin:4,come:2,commerci:4,commonli:4,comput:2,connectedin:4,contain:[],content:[1,3,5],convolut:4,correct:4,cs231n:2,data:4,decid:4,decidehow:[],deep:5,deeplearningbook:[],desir:4,did:2,differ:[2,4],digit:4,directli:4,doe:4,donot:[],draw:2,drive:4,dure:4,dynam:2,each:4,exampl:4,extra:5,f_1:4,f_1_:[],f_2:4,f_3:4,feedforward:4,few:2,figur:2,form:4,forward:2,from:2,get:2,give:2,goal:4,gradient:2,graph:2,had:2,hand:4,has:2,have:[2,4],help:2,here:3,hidden:5,how:4,html:[],http:[],imag:4,implement:[2,4],index:5,individu:[2,4],input:[2,4],instead:4,intmdt:2,intmdt_out:[],introduct:5,isnot:[],kaggl:[],layer:5,layerof:4,learn:[1,4,5],link:3,mani:4,map:4,match:4,math:[],matter:2,method:3,might:4,mlp:4,model:4,modern:5,modul:5,most:4,multilay:4,multipl:2,must:4,mustdecid:[],need:2,network:5,neural:4,node:2,normal:[3,4],note:2,one:2,oper:2,optim:4,order:2,org:[],ormultilay:[],other:4,out:2,output:[2,4],page:5,paper:2,part:5,path:2,perceptron:4,point:4,practic:5,pretti:2,problem:2,process:2,produc:4,prop:2,propag:2,realli:2,recogn:4,recurr:4,reinforc:[1,5],relationship:2,repres:4,respect:2,sai:4,scratch:2,search:5,second:4,see:2,should:[2,4],show:[2,4],simplifi:2,simul:3,some:[2,4],specifi:4,step:2,straigh:2,structur:4,sum:2,test:3,thei:4,them:2,themost:[],theoutput:4,thesecond:[],theyar:[],thi:[2,4],thing:2,those:4,three:4,through:2,time:2,togeth:2,toi:[],too:[],took:2,train:4,two:2,understand:2,use:4,used:4,valu:4,veri:[],wai:2,want:2,what:[2,4],why:5,written:4,www:[],x_center:2,you:2,yourself:2},titles:["Reinforcement Learning","Extra","Batch Normalization","Optimization for Training Deep Models","Part II: Modern Practical Deep Networks","Welcome to dl\u2019s documentation!"],titleterms:{batch:2,boldsymbol:[],call:4,chapter:4,deep:[3,4],document:5,extra:1,hidden:4,indic:5,introduct:4,layer:4,learn:0,method:2,model:3,modern:4,network:4,normal:2,optim:3,part:4,practic:4,reinforc:0,simul:2,tabl:5,train:3,welcom:5,why:4}})