

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>YOLO &mdash; dl 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Part III: Deep Learning Research" href="../../../Part 3 (Deep Learning Research)/index.html" />
    <link rel="prev" title="External Resources On Computer Vision" href="index.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> dl
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../Part 1 (Applied Math and Machine Learning Basics)/index.html">Part I: Applied Math and Machine Learning Basics</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Part II: Modern Practical Deep Networks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../8 Optimization for Training Deep Models/index.html">8 Optimization for Training Deep Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../9 Convolutional Networks/index.html">9 The convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../11 Practical Methodology/index.html">11 Practical Methodoloogy</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">12 Applications</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="index.html">External Resources On Computer Vision</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">YOLO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../Part 3 (Deep Learning Research)/index.html">Part III: Deep Learning Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Extra/index.html">Extra</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">dl</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Part II: Modern Practical Deep Networks</a> &raquo;</li>
        
          <li><a href="../index.html">12 Applications</a> &raquo;</li>
        
          <li><a href="index.html">External Resources On Computer Vision</a> &raquo;</li>
        
      <li>YOLO</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/Part 2 (Modern Practical Deep Networks)/12 Applications/Computer Vision External/YOLO.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="yolo">
<h1>YOLO<a class="headerlink" href="#yolo" title="Permalink to this headline">¶</a></h1>
<p>See <a class="reference external" href="https://arxiv.org/pdf/1506.02640.pdf">Yolo Paper</a></p>
<div class="section" id="intro">
<h2>1. Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h2>
<p>Over all Sturcture/Pipeline:</p>
<ol class="arabic simple">
<li>Resize to 448 * 448</li>
<li>Conv Net</li>
<li>Threshhold the resulting detection by the model’s confidence.</li>
</ol>
<p>A single conv net simultaneously predicts multiple bounding boxes and class probabilities for those boxes. It is trained on full image and directly optimizes detection performance. Benefit over traditional method of object detection.</p>
<ol class="arabic simple">
<li>Fast. Regression problem, no need for complex pipeline. High precision</li>
<li>Reason gloabally about the image when making prediction.</li>
<li>Leans generalizable representation of objects. Less likely to break down when applied to new domain or unexpected inputs.</li>
</ol>
<p>Drawback:
Lag behind state-of-art detection system in accuracy. Struggle to precisely localize some objects. especially small ones</p>
</div>
<div class="section" id="unified-detection">
<h2>2. Unified Detection<a class="headerlink" href="#unified-detection" title="Permalink to this headline">¶</a></h2>
<p>Divide the image into S * S grid. If the center of the an object falls into a grid cell, that grid cell is responsible for detecting that object. Each grid cell predicts B bounding boxes and confidence scores for those boxes. We define confidence as <span class="math notranslate nohighlight">\(Pr(Object) * IOU_{true pred}\)</span>. <a class="reference external" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">IOU</a> is between the predicted box and the groud truth.</p>
<img alt="../../../_images/iou_equation.png" src="../../../_images/iou_equation.png" />
<p>For each <strong>bounding box</strong> (not grid cell), we have 5 prediction cell: x, y, w, h, and confidence.</p>
<ul class="simple">
<li>(x, y) represent the center of the box relative to the bound of the grid cell.</li>
<li>(w, h) represent width and height relative to the whole image</li>
<li>confidence represent IOU between the prediction box and any ground truth box.</li>
</ul>
<p>Each <strong>grid cell</strong> (not bounding box) also predict C conditional class probabilities <span class="math notranslate nohighlight">\(Pr(Class_i | Object)\)</span>. These probabilities are conditioned on the grid cell contraining an object. We only predict one set of class probability per grid cell, regardless of the number of the boxes.</p>
<p>At test time, class-specific confidence scores for each box:</p>
<div class="math notranslate nohighlight">
\[Pr(Class_i | Object) * Pr(Object) * IOU_{true prob} = Pr(Class_i) * IOU_{true prob}\]</div>
<p>These score encode both</p>
<ul class="simple">
<li>probability of that class appearing in the bounding box</li>
<li>How well the predicted box fits the object</li>
</ul>
<img alt="../../../_images/YOLOFigure2.PNG" src="../../../_images/YOLOFigure2.PNG" />
<div class="section" id="network-desgin">
<h3>2.1 Network Desgin<a class="headerlink" href="#network-desgin" title="Permalink to this headline">¶</a></h3>
<img alt="../../../_images/YOLOFigure3.PNG" src="../../../_images/YOLOFigure3.PNG" />
</div>
<div class="section" id="training">
<h3>2.2 Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<ol class="arabic">
<li><p class="first">Pretrain: on ImageNet 1000-class dataset. First 20 conv layers with a fully connected layer.</p>
</li>
<li><p class="first">Convert to perform detection. Add 4 Conv and 2 fully connected with randomly initiated rate. Input resolution 224 * 224 -&gt; 448 * 448</p>
</li>
<li><p class="first">Normalize witdh, height, x, y to be bounded between 0 to 1</p>
</li>
<li><p class="first">Activation</p>
<blockquote>
<div><ol class="loweralpha simple">
<li>Final Layer: Linear Activation</li>
<li>Other latyer: Leaky rectified linear activation function, see equation 2</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">Loss function: sum-squared error</p>
<blockquote>
<div><ol class="loweralpha simple">
<li>Reason: Easy to optimize</li>
<li>Problem: (1) Does not perfectly align with our goal of maximize average precision. (2) In every image many gird cells do not contain any object. This pushes the confidence scores of those cells towards 0, often overpowering the gradient from cells that do contain object.</li>
<li>Solution: increase loss from bounding box coordinate predictions and decrease the loss from confidence predictions from boxes that don’t contain objects. We use two parameters <span class="math notranslate nohighlight">\(\lambda_{coord}\)</span> = 5 and <span class="math notranslate nohighlight">\(\lambda_{noobj}\)</span> = 0.5</li>
<li>Sum-squared error also equally weidgts errors in large boxes and small boxes</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">Only one bounding box should be responsible for each obejct. We assign one predictor to be responsible for predicting an object based on which prediction has the highest current IOU with the ground truth.</p>
</li>
</ol>
<ol class="loweralpha simple">
<li>Loss from bound box coordinate (x, y) Note that the loss comes from one bounding box from one grid cell. Even if obj not in grid cell as ground truth.</li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}
        \lambda_{coord} \sum^{S^2}_{i=0} [(x_i - \hat{x}_i)^2 + (y_i - \hat{y_i})^2] &amp;\text{responsible bounding box} \\
        0 &amp;\text{ other} \\
\end {cases}\end{split}\]</div>
<ol class="loweralpha simple" start="2">
<li>Loss from width w and height h. Note that the loss comes from one bounding box from one grid cell, even if the object is not in the grid cell as ground truth.</li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin {cases}
        \lambda_{coord} \sum^{S^2}_{i=0} [(\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2] &amp;\text{responsible bounding box} \\
        0 &amp;\text{ other} \\
\end {cases}\end{split}\]</div>
<ol class="loweralpha simple" start="3">
<li>Loss from the confidence in each bound box. Not that the loss comes from one bounding box from one grid cel, even if the object is not in the grid cell as ground truth.</li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin {cases}
        \sum^{S^2}_{i=0}(C_i - \hat{C}_i)^2 &amp;\text{obj in grid cell and responsible bounding box} \\
        \lambda_{noobj} \sum^{S^2}_{i=0}(C_i - \hat{C}_i)^2 &amp;\text{obj not in grid cell and responsible bounding box} \\
        0 &amp;\text{other}
\end {cases}\end{split}\]</div>
<ol class="loweralpha simple" start="4">
<li>Loss from the class probability of <strong>grid cell</strong>, only when object is in the grid cell as ground truth.</li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin {cases}
        \sum^{S^2}_{i=0} \sum_{c \in classes} (p_i(c) - \hat{p}_i(c))^2 &amp;\text{obj in grid cell}\\
        0 &amp;\text{other} \\
\end {cases}\end{split}\]</div>
<div class="line-block">
<div class="line">Loss function only penalizes classification if obj is present in the grid cell.</div>
<div class="line">It also penalize bounding box coordinate if that box is responsible for the ground box (highest IOU)</div>
</div>
<p>For generalization.</p>
<ul class="simple">
<li>Use dropout with Dropout rate 0.5.</li>
<li>Data augmentation:random scaling, translation of up to 20% of the original size.</li>
<li>Randomly adjust the exposure and saturation of the image by up to a factor of 1.5 in the HSV color space.</li>
</ul>
</div>
</div>
<div class="section" id="resource">
<h2>Resource<a class="headerlink" href="#resource" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/pdf/1506.02640.pdf">Yolo Paper</a></li>
<li><a class="reference external" href="http://pjreddie.com/yolo/">Project webpage</a></li>
<li><a class="reference external" href="https://arxiv.org/pdf/1311.2524.pdf">RCNN Paper</a></li>
<li><a class="reference external" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">Intersection over Union IOU</a></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../../Part 3 (Deep Learning Research)/index.html" class="btn btn-neutral float-right" title="Part III: Deep Learning Research" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="External Resources On Computer Vision" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Ximing

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>